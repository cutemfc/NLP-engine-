{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37976e3",
   "metadata": {},
   "source": [
    "# Goal: Try the FLAN-T5 model in the prototype, turn the string to structureed parameters for recommender engine use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3376139f",
   "metadata": {},
   "source": [
    "# step 1: import the the housing requests of users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec16a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-06T16:45:55.381060</td>\n",
       "      <td>Diana</td>\n",
       "      <td>ruthm.lin@gmail.com</td>\n",
       "      <td>I would like a apartment nearby the Mitte of B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-07T12:12:20.243206</td>\n",
       "      <td>me</td>\n",
       "      <td>ruthm.lin@gmail.com</td>\n",
       "      <td>I would like a small room but can have a pet ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-07T12:57:01.433639</td>\n",
       "      <td>mei</td>\n",
       "      <td>ruth.lin@gmail.com</td>\n",
       "      <td>I like a 2 rooms and neaby MRT, bus stations. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-07T15:17:56.861578</td>\n",
       "      <td>Diana</td>\n",
       "      <td>ruthm.lin@gmail.com</td>\n",
       "      <td>I would like to 3 bedrooms, nearby the Mitte D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-07T15:27:05.401123</td>\n",
       "      <td>Ruth</td>\n",
       "      <td>ruthm.lin@gmail.com</td>\n",
       "      <td>I would like to have 100m2 and price less than...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp   name                email  \\\n",
       "0  2025-10-06T16:45:55.381060  Diana  ruthm.lin@gmail.com   \n",
       "1  2025-10-07T12:12:20.243206     me  ruthm.lin@gmail.com   \n",
       "2  2025-10-07T12:57:01.433639    mei   ruth.lin@gmail.com   \n",
       "3  2025-10-07T15:17:56.861578  Diana  ruthm.lin@gmail.com   \n",
       "4  2025-10-07T15:27:05.401123   Ruth  ruthm.lin@gmail.com   \n",
       "\n",
       "                                             request  \n",
       "0  I would like a apartment nearby the Mitte of B...  \n",
       "1  I would like a small room but can have a pet ,...  \n",
       "2  I like a 2 rooms and neaby MRT, bus stations. ...  \n",
       "3  I would like to 3 bedrooms, nearby the Mitte D...  \n",
       "4  I would like to have 100m2 and price less than...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the request dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('requests.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b13eb6",
   "metadata": {},
   "source": [
    " # Step 2: Introduce the flan_t5 with fine tuning of house requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b40373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"pip\"\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (4.2.0)\n",
      "Requirement already satisfied: accelerate in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from datasets) (2.0.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (4.57.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from transformers) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/p310/lib/python3.10/site-packages (from requests->transformers) (2025.8.3)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.57.0\n",
      "    Uninstalling transformers-4.57.0:\n",
      "      Successfully uninstalled transformers-4.57.0\n",
      "Successfully installed transformers-4.57.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Introduce the FLAN-T5 model\n",
    "!pip pip install sentencepiece\n",
    "!pip install  datasets accelerate\n",
    "!pip install --upgrade transformers\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments, T5ForConditionalGeneration, T5Tokenizer\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d1e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22fee06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Map:   0%|          | 0/9 [00:00<?, ? examples/s]/opt/anaconda3/envs/p310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 9/9 [00:00<00:00, 205.28 examples/s]\n",
      "/opt/anaconda3/envs/p310/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 1:12:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG14GFamilyCommandBuffer: 0x309f17270>\n",
      "    label = <none> \n",
      "    device = <AGXG14GDevice: 0x301da7600>\n",
      "        name = Apple M2 \n",
      "    commandQueue = <AGXG14GFamilyCommandQueue: 0x1285d6800>\n",
      "        label = <none> \n",
      "        device = <AGXG14GDevice: 0x301da7600>\n",
      "            name = Apple M2 \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG14GFamilyCommandBuffer: 0x308867730>\n",
      "    label = <none> \n",
      "    device = <AGXG14GDevice: 0x301da7600>\n",
      "        name = Apple M2 \n",
      "    commandQueue = <AGXG14GFamilyCommandQueue: 0x1285d6800>\n",
      "        label = <none> \n",
      "        device = <AGXG14GDevice: 0x301da7600>\n",
      "            name = Apple M2 \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG14GFamilyCommandBuffer: 0x158a24310>\n",
      "    label = <none> \n",
      "    device = <AGXG14GDevice: 0x301da7600>\n",
      "        name = Apple M2 \n",
      "    commandQueue = <AGXG14GFamilyCommandQueue: 0x1285d6800>\n",
      "        label = <none> \n",
      "        device = <AGXG14GDevice: 0x301da7600>\n",
      "            name = Apple M2 \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG14GFamilyCommandBuffer: 0x158970d40>\n",
      "    label = <none> \n",
      "    device = <AGXG14GDevice: 0x301da7600>\n",
      "        name = Apple M2 \n",
      "    commandQueue = <AGXG14GFamilyCommandQueue: 0x1285d6800>\n",
      "        label = <none> \n",
      "        device = <AGXG14GDevice: 0x301da7600>\n",
      "            name = Apple M2 \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG14GFamilyCommandBuffer: 0x15898b230>\n",
      "    label = <none> \n",
      "    device = <AGXG14GDevice: 0x301da7600>\n",
      "        name = Apple M2 \n",
      "    commandQueue = <AGXG14GFamilyCommandQueue: 0x1285d6800>\n",
      "        label = <none> \n",
      "        device = <AGXG14GDevice: 0x301da7600>\n",
      "            name = Apple M2 \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG14GFamilyCommandBuffer: 0x159621d80>\n",
      "    label = <none> \n",
      "    device = <AGXG14GDevice: 0x301da7600>\n",
      "        name = Apple M2 \n",
      "    commandQueue = <AGXG14GFamilyCommandQueue: 0x1285d6800>\n",
      "        label = <none> \n",
      "        device = <AGXG14GDevice: 0x301da7600>\n",
      "            name = Apple M2 \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG14GFamilyCommandBuffer: 0x158b85d90>\n",
      "    label = <none> \n",
      "    device = <AGXG14GDevice: 0x301da7600>\n",
      "        name = Apple M2 \n",
      "    commandQueue = <AGXG14GFamilyCommandQueue: 0x1285d6800>\n",
      "        label = <none> \n",
      "        device = <AGXG14GDevice: 0x301da7600>\n",
      "            name = Apple M2 \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG14GFamilyCommandBuffer: 0x158bac270>\n",
      "    label = <none> \n",
      "    device = <AGXG14GDevice: 0x301da7600>\n",
      "        name = Apple M2 \n",
      "    commandQueue = <AGXG14GFamilyCommandQueue: 0x1285d6800>\n",
      "        label = <none> \n",
      "        device = <AGXG14GDevice: 0x301da7600>\n",
      "            name = Apple M2 \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG14GFamilyCommandBuffer: 0x159529cd0>\n",
      "    label = <none> \n",
      "    device = <AGXG14GDevice: 0x301da7600>\n",
      "        name = Apple M2 \n",
      "    commandQueue = <AGXG14GFamilyCommandQueue: 0x1285d6800>\n",
      "        label = <none> \n",
      "        device = <AGXG14GDevice: 0x301da7600>\n",
      "            name = Apple M2 \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9, training_loss=37.83454047309028, metrics={'train_runtime': 4390.2016, 'train_samples_per_second': 0.006, 'train_steps_per_second': 0.002, 'total_flos': 5019043627008.0, 'train_loss': 37.83454047309028, 'epoch': 3.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create dataset \n",
    "data = [\n",
    "    {'input_text': 'I would like a apartment nearby the Mitte of Berlin, 2 bedrooms close to parks, rent price less than 2000, I am a wheelchair',\n",
    "     \"slots\": {\"district\": \"Mitte\", \"price\": \"<2000\", \"bedrooms\": \"2\", \"proximity_park\": \">0.9\", \"wheelchair_accessabil\": \">0.9\", \"proximity_schools\": \"any\", \"proximity_kindergarten\": \"any\", \"proximity_university\": \"any\"}},\n",
    "    {'input_text': 'I would like a small room but can have a pet , price is less than $200',\n",
    "     \"slots\": {\"district\": \"any\", \"price\": \"<200\", \"bedrooms\": \"1\", \"proximity_park\": \"any\", \"pet_friendly\": \">0.9\"}},\n",
    "    {'input_text': 'I like a 2 rooms and neaby MRT, bus stations. The price is less than $2000',\n",
    "     \"slots\": {\"district\": \"any\", \"price\": \"<2000\", \"bedrooms\": \"2\", \"proximity_MRT\": \">0.9\", \"proximity_bus\": \">0.9\"}},\n",
    "    {'input_text': 'I would like to 3 bedrooms, nearby the Mitte District, and rent price less than 2000',\n",
    "     \"slots\": {\"district\": \"Mitte\", \"price\": \"<2000\", \"bedrooms\": \"3\", \"proximity_park\": \"any\", \"proximity_MRT\": \"any\"}},\n",
    "    {'input_text': 'I would like to have 100m2 and price less than 1000 Euro',\n",
    "     \"slots\": {\"district\": \"any\", \"price\": \"<1000\", \"size\": \">100\"}},\n",
    "    {'input_text': 'I want a 3 bedrooms apartment, nearby the Kreuzberg District, and rent price less than 2500',\n",
    "     \"slots\": {\"district\": \"Kreuzberg\", \"price\": \"<2500\", \"bedrooms\": \"3\", \"proximity_park\": \"any\", \"proximity_MRT\": \"any\"}},\n",
    "    {'input_text': 'I would like a studio apartment, pet friendly, rent price less than 1500',\n",
    "     \"slots\": {\"district\": \"any\", \"price\": \"<1500\", \"bedrooms\": \"1\", \"pet_friendly\": \">0.9\"}},\n",
    "    {'input_text': 'I need a 1 bedroom apartment, close to schools and kindergartens, rent price less than 1800',\n",
    "     \"slots\": {\"district\": \"any\", \"price\": \"<1800\", \"bedrooms\": \"1\", \"proximity_schools\": \">0.9\", \"proximity_kindergarten\": \">0.9\"}},\n",
    "    {'input_text': 'I am looking for a 4 bedrooms house, near universities, rent price less than 3000',\n",
    "     \"slots\": {\"district\": \"any\", \"price\": \"<3000\", \"bedrooms\": \"4\", \"proximity_university\": \">0.9\"}}\n",
    "]\n",
    "\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "# Load FLAN-T5 model and tokenizer\n",
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(examples):\n",
    "    inputs = examples[\"input_text\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    # Convert slot dicts to JSON strings\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            [ str(s) for s in examples[\"slots\"]],\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True)\n",
    "\n",
    "# Training settings to fine-tune the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./flan_t5_house_rental\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5327a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model with user input\n",
    "def predict_slots(input_text):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=512)\n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return decoded_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9160d253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./flan_t5_house_rental/tokenizer_config.json',\n",
       " './flan_t5_house_rental/special_tokens_map.json',\n",
       " './flan_t5_house_rental/spiece.model',\n",
       " './flan_t5_house_rental/added_tokens.json')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model and tokenizer\n",
    "model.save_pretrained(\"./flan_t5_house_rental\")\n",
    "tokenizer.save_pretrained(\"./flan_t5_house_rental\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1465b475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"  # change from \"mps\" or \"cuda\"\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d97deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 bedrooms close to parks and kindergarten, size is greater 100m2, rent price less than 2000\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "test_input = \"I would like a apartment nearby the Mitte of Berlin, 3 bedrooms close to parks and kindergarten, size is greater 100m2, rent price less than 2000\"\n",
    "predicted_slots = predict_slots(test_input)\n",
    "print(predicted_slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a70a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the output format to json\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f971cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"district\": \"any\",\n",
      "  \"price\": \"<2000\",\n",
      "  \"bedrooms\": \"3\",\n",
      "  \"proximity_park\": \">0.9\",\n",
      "  \"proximity_kindergarten\": \">0.9\",\n",
      "  \"wheelchair_accessabil\": \"any\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ignore this\n",
    "# change the output format to json\n",
    "\n",
    "# Load your saved model and tokenizer\n",
    "model_name = \"./flan_t5_house_rental\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "def predict_slots(input_text):\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=512)\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Basic text post-processing\n",
    "    decoded_lower = decoded.lower()\n",
    "\n",
    "    result = {\n",
    "        \"district\": \"mitte\" if \"mitte\" in decoded_lower else \"any\",\n",
    "        \"price\": re.findall(r'less than (\\d+)', decoded_lower),\n",
    "        \"bedrooms\": re.findall(r'(\\d+) bedroom', decoded_lower) or re.findall(r'(\\d+) rooms?', decoded_lower),\n",
    "        \"proximity_park\": \">0.9\" if \"park\" in decoded_lower else \"any\",\n",
    "        \"proximity_kindergarten\": \">0.9\" if \"kindergarten\" in decoded_lower else \"any\",\n",
    "        \"wheelchair_accessabil\": \">0.9\" if \"wheelchair\" in decoded_lower else \"any\"\n",
    "    }\n",
    "\n",
    "    # Clean up results\n",
    "    result[\"price\"] = f\"<{result['price'][0]}\" if result[\"price\"] else \"any\"\n",
    "    result[\"bedrooms\"] = result[\"bedrooms\"][0] if result[\"bedrooms\"] else \"any\"\n",
    "\n",
    "    return json.dumps(result, indent=2)\n",
    "\n",
    "# Test it\n",
    "test_input = \"I would like a apartment nearby the Mitte of Berlin, 3 bedrooms close to parks and kindergarten, size greater 100m2, rent price less than 2000\"\n",
    "print(predict_slots(test_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fafa67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"district\": \"Mitte\",\n",
      "  \"size\": \">100m2\",\n",
      "  \"price\": \"<2000\",\n",
      "  \"bedrooms\": \"3\",\n",
      "  \"transport_accessible\": \">0.9\",\n",
      "  \"convenient_accessible\": \">0.9\",\n",
      "  \"family_friendly\": \">0.9\",\n",
      "  \"greenspace_accessible\": \">0.9\",\n",
      "  \"healthcare_accessible\": \"any\",\n",
      "  \"safety_score\": \"any\",\n",
      "  \"nightlife_accessible\": \"any\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Add the other features of request\n",
    "\n",
    "# Load model\n",
    "model_name = \"./flan_t5_house_rental\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# List of Berlin districts for matching\n",
    "berlin_districts = [\n",
    "    \"mitte\", \"friedrichshain\", \"kreuzberg\", \"charlottenburg\", \"spandau\",\n",
    "    \"steglitz\", \"zehlendorf\", \"tempelhof\", \"schoeneberg\", \"neukoelln\",\n",
    "    \"treptow\", \"koepenick\", \"marzahn\", \"hellersdorf\", \"lichtenberg\", \"pankow\"\n",
    "]\n",
    "\n",
    "def predict_slots(input_text):\n",
    "    # Generate model prediction\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=512)\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    decoded_lower = decoded.lower()\n",
    "\n",
    "    # --- Basic info extraction ---\n",
    "    district = next((d for d in berlin_districts if d in decoded_lower), \"any\")\n",
    "    bedrooms = re.findall(r'(\\d+)\\s*(?:bedroom|room)s?', decoded_lower)\n",
    "    price = re.findall(r'(?:less than|under|below)\\s*(\\d+)', decoded_lower)\n",
    "    size = re.findall(r'(?:greater than|over|more than|above)\\s*(\\d+)\\s*(?:m2|square meters?)?', decoded_lower)\n",
    "\n",
    "    # --- Thematic accessibility checks ---\n",
    "    transport_keywords = [\"bus\", \"subway\", \"ubahn\", \"train\", \"transport\"]\n",
    "    convenient_keywords = [\"post\", \"atm\", \"bank\", \"cafe\", \"restaurant\", \"supermarket\"]\n",
    "    family_keywords = [\"school\", \"kindergarten\", \"playground\"]\n",
    "    greenspace_keywords = [\"park\", \"forest\", \"pool\", \"lake\"]\n",
    "    healthcare_keywords = [\"hospital\", \"clinic\", \"pharmacy\", \"dentist\"]\n",
    "    safety_keywords = [\"crime\", \"safe\", \"safety\"]\n",
    "    nightlife_keywords = [\"bar\", \"club\", \"nightlife\"]\n",
    "\n",
    "    def check_keywords(keywords):\n",
    "        return \">0.9\" if any(k in decoded_lower for k in keywords) else \"any\"\n",
    "\n",
    "    result = {\n",
    "        \"district\": district.title(),\n",
    "        \"size\": f\">{size[0]}m2\" if size else \"any\",\n",
    "        \"price\": f\"<{price[0]}\" if price else \"any\",\n",
    "        \"bedrooms\": bedrooms[0] if bedrooms else \"any\",\n",
    "        \"transport_accessible\": check_keywords(transport_keywords),\n",
    "        \"convenient_accessible\": check_keywords(convenient_keywords),\n",
    "        \"family_friendly\": check_keywords(family_keywords),\n",
    "        \"greenspace_accessible\": check_keywords(greenspace_keywords),\n",
    "        \"healthcare_accessible\": check_keywords(healthcare_keywords),\n",
    "        \"safety_score\": check_keywords(safety_keywords),\n",
    "        \"nightlife_accessible\": check_keywords(nightlife_keywords)\n",
    "    }\n",
    "\n",
    "    return json.dumps(result, indent=2)\n",
    "\n",
    "# Test it\n",
    "test_input = \"I would like an apartment nearby the Mitte of Berlin, 3 bedrooms close to parks and kindergarten, size greater than 100m2, rent price less than 2000, near subway and cafes.\"\n",
    "print(predict_slots(test_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52bd6a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"district\": \"Spandau\",\n",
      "  \"size\": \">100m2\",\n",
      "  \"price\": \"<1500\",\n",
      "  \"bedrooms\": \"3\",\n",
      "  \"transport_accessible\": \">0.9\",\n",
      "  \"convenient_accessible\": \"any\",\n",
      "  \"family_friendly\": \"any\",\n",
      "  \"greenspace_accessible\": \"any\",\n",
      "  \"healthcare_accessible\": \">0.9\",\n",
      "  \"safety_score\": \">0.9\",\n",
      "  \"nightlife_accessible\": \"any\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "test_input= \" I would like to live in Spandau, low crime ratio, and 3 bedroom, size greater than 100, nearby supermarkt, neaby public transport and easy to find the clinics, the price less than 1500euro.\"\n",
    "print(predict_slots(test_input))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce9adc",
   "metadata": {},
   "source": [
    "# step 3 : save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9a739cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the above renewed model, the output format is json and cleaned results\n",
    "model.save_pretrained(\"./flan_t5_house_rental_json_rev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d15784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1:\n",
      "Input: I want a 2 bedroom apartment in Mitte with rent under 2000\n",
      "Predicted Slots: {'district': 'Mitte', 'size': 'any', 'price': '<2000', 'bedrooms': '2', 'transport_accessible': 'any', 'convenient_accessible': 'any', 'family_friendly': 'any', 'greenspace_accessible': 'any', 'healthcare_accessible': 'any', 'safety_score': 'any', 'nightlife_accessible': 'any'}\n",
      "True Slots: {'district': 'Mitte', 'price': '<2000', 'bedrooms': '2', 'proximity_park': 'any', 'proximity_kindergarten': 'any', 'wheelchair_accessabil': 'any'}\n",
      "Match: False\n",
      "--------------------------------------------------\n",
      "Test Case 2:\n",
      "Input: Looking for a studio apartment, pet friendly  and rent below 1500\n",
      "Predicted Slots: {'district': 'Any', 'size': 'any', 'price': 'any', 'bedrooms': 'any', 'transport_accessible': 'any', 'convenient_accessible': 'any', 'family_friendly': 'any', 'greenspace_accessible': 'any', 'healthcare_accessible': 'any', 'safety_score': 'any', 'nightlife_accessible': 'any'}\n",
      "True Slots: {'district': 'any', 'price': '<1500', 'bedrooms': '1', 'pet_friendly': '>0.9', 'proximity_park': 'any', 'proximity_kindergarten': 'any', 'wheelchair_accessabil': 'any'}\n",
      "Match: False\n",
      "--------------------------------------------------\n",
      "Test Case 3:\n",
      "Input: Need a 3 bedroom house near schools, rent max 2500\n",
      "Predicted Slots: {'district': 'Any', 'size': 'any', 'price': 'any', 'bedrooms': '3', 'transport_accessible': 'any', 'convenient_accessible': 'any', 'family_friendly': '>0.9', 'greenspace_accessible': 'any', 'healthcare_accessible': 'any', 'safety_score': 'any', 'nightlife_accessible': 'any'}\n",
      "True Slots: {'district': 'any', 'price': '<2500', 'bedrooms': '3', 'proximity_schools': '>0.9', 'proximity_kindergarten': 'any', 'wheelchair_accessabil': 'any'}\n",
      "Match: False\n",
      "--------------------------------------------------\n",
      "Test Case 4:\n",
      "Input: Searching for a 1 bedroom apartment in Kreuzberg, price under 1800\n",
      "Predicted Slots: {'district': 'Kreuzberg', 'size': 'any', 'price': 'any', 'bedrooms': '1', 'transport_accessible': 'any', 'convenient_accessible': 'any', 'family_friendly': 'any', 'greenspace_accessible': 'any', 'healthcare_accessible': 'any', 'safety_score': 'any', 'nightlife_accessible': 'any'}\n",
      "True Slots: {'district': 'Kreuzberg', 'price': '<1800', 'bedrooms': '1', 'proximity_park': 'any', 'proximity_kindergarten': 'any', 'wheelchair_accessabil': 'any'}\n",
      "Match: False\n",
      "--------------------------------------------------\n",
      "Test Case 5:\n",
      "Input: I want a 4 bedroom house near universities with rent less than 3000\n",
      "Predicted Slots: {'district': 'Any', 'size': 'any', 'price': 'any', 'bedrooms': 'any', 'transport_accessible': 'any', 'convenient_accessible': 'any', 'family_friendly': 'any', 'greenspace_accessible': 'any', 'healthcare_accessible': 'any', 'safety_score': 'any', 'nightlife_accessible': 'any'}\n",
      "True Slots: {'district': 'any', 'price': '<3000', 'bedrooms': '4', 'proximity_university': '>0.9', 'proximity_park': 'any', 'proximity_kindergarten': 'any', 'wheelchair_accessabil': 'any'}\n",
      "Match: False\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluation with some test cases\n",
    "test_cases = [\n",
    "    (\"I want a 2 bedroom apartment in Mitte with rent under 2000\",\n",
    "     {\"district\": \"Mitte\", \"price\": \"<2000\", \"bedrooms\": \"2\", \"proximity_park\": \"any\", \"proximity_kindergarten\": \"any\", \"wheelchair_accessabil\": \"any\"}),\n",
    "    (\"Looking for a studio apartment, pet friendly  and rent below 1500\",\n",
    "     {\"district\": \"any\", \"price\": \"<1500\", \"bedrooms\": \"1\", \"pet_friendly\": \">0.9\", \"proximity_park\": \"any\", \"proximity_kindergarten\": \"any\", \"wheelchair_accessabil\": \"any\"}),\n",
    "    (\"Need a 3 bedroom house near schools, rent max 2500\",\n",
    "     {\"district\": \"any\", \"price\": \"<2500\", \"bedrooms\": \"3\", \"proximity_schools\": \">0.9\", \"proximity_kindergarten\": \"any\", \"wheelchair_accessabil\": \"any\"}),\n",
    "    (\"Searching for a 1 bedroom apartment in Kreuzberg, price under 1800\",\n",
    "     {\"district\": \"Kreuzberg\", \"price\": \"<1800\", \"bedrooms\": \"1\", \"proximity_park\": \"any\", \"proximity_kindergarten\": \"any\", \"wheelchair_accessabil\": \"any\"}),\n",
    "    (\"I want a 4 bedroom house near universities with rent less than 3000\",\n",
    "     {\"district\": \"any\", \"price\": \"<3000\", \"bedrooms\": \"4\", \"proximity_university\": \">0.9\", \"proximity_park\": \"any\", \"proximity_kindergarten\": \"any\", \"wheelchair_accessabil\": \"any\"})\n",
    "]\n",
    "# Evalute the model\n",
    "for i, (input_text, true_slots) in enumerate(test_cases):\n",
    "    predicted_json = predict_slots(input_text)\n",
    "    predicted_slots = json.loads(predicted_json)\n",
    "    print(f\"Test Case {i+1}:\")\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(f\"Predicted Slots: {predicted_slots}\")\n",
    "    print(f\"True Slots: {true_slots}\")\n",
    "    print(f\"Match: {predicted_slots == true_slots}\")\n",
    "    print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ddc520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using accuracy and F1-score to evaluate the model\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d37fd9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy and F1-score calculation\n",
    "def calculate_metrics(true_slots, predicted_slots):\n",
    "    true_values = []\n",
    "    pred_values = []\n",
    "    \n",
    "    for key in true_slots.keys():\n",
    "        true_values.append(true_slots[key])\n",
    "        pred_values.append(predicted_slots.get(key, \"any\"))\n",
    "    \n",
    "    accuracy = accuracy_score(true_values, pred_values)\n",
    "    f1 = f1_score(true_values, pred_values, average='weighted', zero_division=1)\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "779a6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89bb1d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5\n",
      "Overall F1 Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "#test the model and calculate metrics\n",
    "# load requests.csv\n",
    "df_requests = pd.read_csv('requests.csv')\n",
    "cases = df_requests['request'].tolist()\n",
    "# test all cases\n",
    "predicted_slots_list = []\n",
    "true_slots_list = []\n",
    "for case in cases:\n",
    "    predicted_json = predict_slots(case)\n",
    "    predicted_slots = json.loads(predicted_json)\n",
    "    predicted_slots_list.append(predicted_slots)\n",
    "    \n",
    "    # Here we assume true slots are available in the dataframe for evaluation\n",
    "    # In practice, you would have a separate column or dataset with true slots\n",
    "    # For demonstration, we will use dummy true slots\n",
    "    true_slots = {\n",
    "        \"district\": \"any\",\n",
    "        \"price\": \"<2000\",\n",
    "        \"bedrooms\": \"2\",\n",
    "        \"proximity_park\": \"any\",\n",
    "        \"proximity_kindergarten\": \"any\",\n",
    "        \"wheelchair_accessabil\": \"any\"\n",
    "    }\n",
    "    true_slots_list.append(true_slots)\n",
    "\n",
    "# Calculate overall metrics\n",
    "all_true_slots = {}\n",
    "all_pred_slots = {}\n",
    "for true, pred in zip(true_slots_list, predicted_slots_list):\n",
    "    all_true_slots.update(true)\n",
    "    all_pred_slots.update(pred) \n",
    "accuracy, f1 = calculate_metrics(all_true_slots, all_pred_slots)\n",
    "print(f\"Overall Accuracy: {accuracy}\")\n",
    "print(f\"Overall F1 Score: {f1}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2dfcf2",
   "metadata": {},
   "source": [
    "When we increase the features, the accuracy and F1 lower dowm than only 4-5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee720da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p310/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5457f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.18 (main, Jun  5 2025, 08:37:47) [Clang 14.0.6 ]\n",
      "Transformers version: 4.57.0\n",
      "PyTorch version: 2.8.0\n",
      "CUDA available: False\n",
      "SentencePiece version: 0.2.1\n"
     ]
    }
   ],
   "source": [
    "# 1️⃣ check Python \n",
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "# 2️⃣ check transformers \n",
    "import transformers\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "\n",
    "# 3️⃣ check PyTorch \n",
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# 4️⃣ check SentencePiece install（T5Tokenizer needed）\n",
    "import sentencepiece\n",
    "print(\"SentencePiece version:\", sentencepiece.__version__)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
