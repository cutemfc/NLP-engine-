# Goal: Prepare three NLP models 

## Scripts / Models:
1. **FLAN-T5 model**: A versatile instruction-tuned transformer capable of performing a wide range of NLP tasks by following natural language prompts.

2. **Valhalla DistilBART-MNLI model**: A lightweight distilled version of BART fine-tuned on the MNLI dataset for efficient and accurate natural language inference.

3. **BERT-based uncased model**: A bidirectional transformer trained on masked word prediction and next sentence prediction tasks, enabling deep contextual understanding of English text.
